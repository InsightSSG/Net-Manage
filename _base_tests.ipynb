{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c004ea-e387-4217-b0ae-1f3ee2c42eea",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88522282-9d1b-405b-bd4f-706a1c40a458",
   "metadata": {},
   "source": [
    "This notebook provides the base for suites of tests to run before, during and \n",
    "after maintenance windows.\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "1. Create a spreadsheet that contains at least one workbook\n",
    "    1. Put the name of one or more tests as column headers\n",
    "    1. Put one or more device groups in each column\n",
    "1. Enter the name of the spreadsheet and workbook when prompted below\n",
    "1. Enter a filename to save the output to (it will be saved as a spreadsheet with a separate workbook for each test's output)\n",
    "1. Run the \"pre-check\" cells\n",
    "1. If you would like to run post-checks and compare the data, then run the \"post-check\" cells\n",
    "    1. There is an option to import the results from the spreadsheet outputted in the pre-checks, so that post-checks can be run at a later date\n",
    "\n",
    "**Methodology:**\n",
    "1. Use Ansible-runner to execute Ansible playbooks, then return the output to Python for analysis\n",
    "    1. If Ansible cannot be used for some reason, then an API or Netmiko can be used instead\n",
    "1. I am coding this in Jupyter to allow for easy testing, but it can be ported to its own script(s) or a GUI later\n",
    "1. I would like to coordinate with the authors of Get-Inventory to see if the functions can be re-used in that tool\n",
    "\n",
    "**Functions:**\n",
    "\n",
    "The following functions are preliminary; more will be added as planning continues.\n",
    "\n",
    "1. **Cisco**\n",
    "    1. **NXOS**\n",
    "        1. Interface status\n",
    "        1. Trunk / Port-channel status\n",
    "        1. Spanning-tree (blocked ports, err-disabled ports, log entries)\n",
    "        1. VPC status\n",
    "        1. VLAN database\n",
    "        1. ARP table (including in VRFs)\n",
    "        1. CAM table\n",
    "        1. Routes (including routes in VRFs)\n",
    "        1. Routing neighbors\n",
    "        1. VRFs\n",
    "    1. **IOS / IOS-XE**\n",
    "        1. Interface status\n",
    "        1. Trunk / Port-channel status\n",
    "        1. Spanning-tree (blocked ports, err-disabled ports, log entries)\n",
    "        1. VLAN database\n",
    "        1. ARP table (including in VRFs)\n",
    "        1. CAM table\n",
    "        1. Routes (including routes in VRFs)\n",
    "        1. Routing neighbors\n",
    "        1. VRFs\n",
    "    1. **ASA (most functions are TBD)**\n",
    "        1. Interface status\n",
    "        1. Firewall rules\n",
    "    1. **Meraki**\n",
    "        1. TBD\n",
    "1. **F5**\n",
    "    1. **F5 LTM**\n",
    "        1. Interface status\n",
    "        1. Trunk status\n",
    "        1. VLANs\n",
    "        1. ARP table\n",
    "        1. CAM table\n",
    "        1. Routes\n",
    "        1. Active VIPs\n",
    "        1. Active Pools\n",
    "        1. Active Pool Members\n",
    "        1. Basic VIP testing (tentative plan is to use NMAP to check if expected ports are up)\n",
    "        1. iRules (iRule syntax can change between software versions)\n",
    "        1. iRule-specific testing (will vary by customer; for this customer, I will test HTTP redirects)\n",
    "        1. **Future Functions That Can Be Added If Necessary:**\n",
    "            1. Route domains\n",
    "            1. Routing neighbors\n",
    "            1. Spanning-tree\n",
    "    1. **F5 Big-IQ**\n",
    "        1. **TBD**\n",
    "1. **Palo Alto**\n",
    "    1. TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1de12-88dc-43ce-a739-b013cc5d08e7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e342c1-3442-4c84-ac2a-b7f387ff6493",
   "metadata": {},
   "source": [
    "## Import Modules and Set Various Parameters\n",
    "\n",
    "This cell updates the MAC vendor database, which can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fc48e-7d4e-4945-91de-bfa567fc1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ansible\n",
    "import ansible_runner\n",
    "import helpers as hp\n",
    "import network_funcs\n",
    "# import ipaddress\n",
    "import nest_asyncio\n",
    "import validators as vd\n",
    "# import nmap3\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pykeepass\n",
    "# import requests\n",
    "import sys\n",
    "# import yaml  # Remove after testing is done, because it is imported by the helpers library\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from getpass import getpass\n",
    "from pykeepass import PyKeePass\n",
    "from IPython.display import display, HTML\n",
    "from mac_vendor_lookup import MacLookup\n",
    "from pprint import pprint\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "nb_path = str(pathlib.Path().resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8b831-d333-4caa-9994-28e6d3e0e9c9",
   "metadata": {},
   "source": [
    "## Define Test Variables and Get User Credentials\n",
    "\n",
    "Provide the necessary information in the following cell.\n",
    "\n",
    "Provide the following data:\n",
    "- Absolute path to the Keepass database containing tenant information\n",
    "- Password to the Keepass Database\n",
    "- Group Name\n",
    "\n",
    "The group should contain the following entries (be sure the titles match):\n",
    "- 'Tenant'\n",
    "  - Contains the SSH username and password\n",
    "- 'Net-Manage Path'\n",
    "  - The path to the Net-Manage repository (put it in the 'URL' field)\n",
    "- 'Ansible Private Data Directory'\n",
    "  - The path to the Ansible Private Data Directory (in the 'URL' field)\n",
    "- 'Tests File'\n",
    "  - The path to the CSV file containing the tests to run\n",
    "\n",
    "**TODO:** Add support for using different credentials for devices.\n",
    "\n",
    "Here are example screenshots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6939b8-c077-4aac-99a1-a820dbf8d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_path = getpass('Enter the path to the Keepass database: ')\n",
    "kp_path = os.path.expanduser(kp_path)\n",
    "kp_pass = getpass('Enter your password to the Keepass database: ')\n",
    "kp_group = getpass('Enter the group name that contains tenant data: ')\n",
    "\n",
    "kp = PyKeePass(kp_path, kp_pass)\n",
    "kp_group = kp.find_groups(name=kp_group, first=True)\n",
    "\n",
    "uname = kp.find_entries(title='Tenant', group=kp_group)[0].username\n",
    "pw = kp.find_entries(title='Tenant', group=kp_group)[0].password\n",
    "nm = kp.find_entries(title='Net-Manage Path', group=kp_group)[0].url\n",
    "tfile = kp.find_entries(title='Tests File', group=kp_group)[0].url\n",
    "pdir = kp.find_entries(title='Private Data Dir', group=kp_group)[0].url\n",
    "private_data_dir = os.path.expanduser(pdir)\n",
    "\n",
    "df_tests, df_vars, nm_path, play_path, test_map = hp.map_tests_to_os(pdir,\n",
    "                                                                     nm,\n",
    "                                                                     tfile)\n",
    "\n",
    "display(HTML('<h3>Tests to Run</h3>'))\n",
    "display(df_tests)\n",
    "\n",
    "display(HTML('<h3>Host Group Variables</h3>'))\n",
    "display(df_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfef0d5-891a-4128-9b16-964ed76bacbe",
   "metadata": {},
   "source": [
    "# Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490e460-9085-4c66-9609-4043b8c720a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(network_funcs)\n",
    "# Create a list of the columns in the df_tests dataframe. Each column will\n",
    "# represent a host group.\n",
    "cols = df_tests.columns.to_list()\n",
    "\n",
    "# Iterate through the dictionary of tests. For each test, search the df_tests\n",
    "# dataframe to see if the user requested that test. If they did, run the test\n",
    "# and store the results in the 'test_map' dictionary.\n",
    "for key, value in test_map.items():\n",
    "    for c in cols:\n",
    "        hostgroup = df_tests.loc[key][c]\n",
    "        # If a test is requested, get the test name, ansible_network_os, and\n",
    "        # playbook.\n",
    "        if hostgroup != 'nan':\n",
    "            test_name = key\n",
    "            row = df_vars.loc[df_vars['host_group'] == hostgroup]\n",
    "            ansible_os = row['ansible_network_os'][c]\n",
    "            playbook = value.get(ansible_os)['playbook']\n",
    "            result = nf.run_test(ansible_os,\n",
    "                                 test_name,\n",
    "                                 uname,\n",
    "                                 pw,\n",
    "                                 hostgroup,\n",
    "                                 play_path,\n",
    "                                 private_data_dir,\n",
    "                                 nm_path)\n",
    "            test_map[key][ansible_os]['result'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac26794-ca4d-47f4-8554-29b51eb3c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_map.items():\n",
    "    if key == test_name:\n",
    "        for k, v in value.items():\n",
    "            result = value.get('cisco.nxos.nxos')['result']\n",
    "            break\n",
    "# display(result)\n",
    "# df = result.loc[result['Device'] == 'CTS-CORE-SWT2'].copy()\n",
    "display(result.info())\n",
    "# display(result.loc[result['vendor'] == 'unknown'].info())\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7be65f-b9d6-4b96-b96d-42facf145506",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d57846-3491-42b6-93cb-f592896d5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_map.items():\n",
    "    if key == 'arp_table':\n",
    "        for k, v in value.items():\n",
    "            result = value.get('paloaltonetworks.panos')['result']\n",
    "            break                \n",
    "df = result.loc[result['Interface'] == 'vlan.123'].copy()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "import socket\n",
    "\n",
    "reverse_dns = list()\n",
    "for idx, row in df.iterrows():\n",
    "    address = row['Address']\n",
    "    try:\n",
    "        rdns = socket.getnameinfo((address, 0), 0)[0]\n",
    "    except Exception:\n",
    "        rdns = 'unknown'\n",
    "    reverse_dns.append(rdns)\n",
    "\n",
    "df['Reverse DNS'] = reverse_dns\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ba933-5c2d-4e27-91d0-f0790102459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display NXOS Pre-checks\n",
    "\n",
    "for key, value in test_map.items():\n",
    "    for k, v in value.items():        \n",
    "        if key == 'pre_post_checks':\n",
    "            try:\n",
    "                if pre_results:\n",
    "                    pass\n",
    "            except Exception:\n",
    "                pre_results = value.get('cisco.nxos.nxos')['result']\n",
    "            break\n",
    "\n",
    "print('Available Dataframes:')\n",
    "for key, value in pre_results.items():\n",
    "    print(key)\n",
    "\n",
    "display(pre_results['df_hostnames'])\n",
    "display(pre_results['df_vpc_state'])\n",
    "display(pre_results['df_vpc_status'])\n",
    "display(len(pre_results['df_inf_status']))\n",
    "\n",
    "df = pre_results['df_inf_status']\n",
    "display(len(df.loc[df['Status'] == 'connected']))\n",
    "display(df.loc[df['Status'] == 'connected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fb222-06d6-41ed-a0db-731dfff3da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91ed6f-c83c-408f-93fe-5091b9ffcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display NXOS Post-checks\n",
    "\n",
    "for key, value in test_map.items():\n",
    "    for k, v in value.items():        \n",
    "        if key == 'pre_post_checks':\n",
    "            try:\n",
    "                if post_results:\n",
    "                    pass\n",
    "            except Exception:\n",
    "                post_results = value.get('cisco.nxos.nxos')['result']\n",
    "            break\n",
    "\n",
    "print('Available Dataframes:')\n",
    "for key, value in post_results.items():\n",
    "    print(key)\n",
    "\n",
    "display(post_results['df_hostnames'])\n",
    "display(post_results['df_vpc_state'])\n",
    "display(post_results['df_vpc_status'])\n",
    "display(len(post_results['df_inf_status']))\n",
    "\n",
    "df = post_results['df_inf_status']\n",
    "display(len(df.loc[df['Status'] == 'connected']))\n",
    "display(df.loc[df['Status'] == 'connected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b9cb0-f381-43ab-adb5-25dad501b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_map.items():\n",
    "    for k, v in value.items():\n",
    "        df = v.get('result')\n",
    "        if df is not None:\n",
    "            display(v.get('result'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ec15a-9b57-45ab-85da-6dd6219439b0",
   "metadata": {},
   "source": [
    "## Create the Dictionary to Store Pre- and Post-check DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea1a88-b8d7-4b90-9ea0-a6cea2c19a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = dict()\n",
    "checks['f5s'] = dict()\n",
    "checks['nxos'] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c9243-47a3-4f79-96ce-294cf6895700",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Create a DataFrame Containing the Tests to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0eb84-e4e5-4eca-80be-56e3d355a0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c57829d-1238-40d9-b7e9-fe5fd5a42bd5",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbd289-facc-4f52-9eaa-4dfc34e1f110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cisco Pre-checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ada01-a4de-4e84-85ec-87f43aba6d03",
   "metadata": {},
   "source": [
    "### Cisco NXOS Pre-checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29e28d-dc63-48f7-b5f6-7400f3878c77",
   "metadata": {},
   "source": [
    "Runs the following tests:\n",
    "* Get running-config diff\n",
    "* Get err-disabled interfaces\n",
    "* Get logs of err-disabled interfaces (to check for interfaces that auto-recovered)\n",
    "* Get spanning-tree blocked ports\n",
    "* Get VPC state\n",
    "* Get VPC consistency\n",
    "* Get VPC peer-keepalive\n",
    "\n",
    "**ToDo:**\n",
    "\n",
    "* Get ARP table\n",
    "* Get CAM table (?)\n",
    "\n",
    "\n",
    "\n",
    "    commands = {'diff_command': 'show running-config diff',\n",
    "                'interface_status_command': 'show interface status err-disabled',\n",
    "                'logging_command': 'show logging last 9999 | grep \"err-disable\\|BPDU\"',\n",
    "                'stp_blocked_ports_command': 'show spanning-tree blockedports',\n",
    "                'vpc_brief_command': 'show vpc brief | grep Po',\n",
    "                'vpc_consistency_command': 'show vpc consistency-parameters global | grep \"Local suspended\"',\n",
    "                'vpc_keepalive_command': 'show vpc peer-keepalive | grep -v \"ms\\|msec\"'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e65e4-ca51-4399-981a-5051c6a6a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cisco_nxos_run_checks(username,\n",
    "                          password,\n",
    "                          host_group,\n",
    "                          play_path,\n",
    "                          private_data_dir):\n",
    "    '''\n",
    "    Run the pre- and post-checks on a Cisco NXOS and adds the results to\n",
    "    a dictionary. Also creates a list of devices in the host group.\n",
    "    \n",
    "    Args:\n",
    "        username (str):         The username to login to devices\n",
    "        password (str):         The password to login to devices\n",
    "        host_group (str):       The inventory host group\n",
    "        play_path (str):        The path to the playbooks directory\n",
    "        private_data_dir (str): The path to the Ansible private data directory\n",
    "\n",
    "    Returns:\n",
    "        devices (list):    A list of devices in the host group\n",
    "        check_data (dict): A dictionary containing the pre-checks\n",
    "    '''\n",
    "    # Create the base variables\n",
    "    check_data = dict()\n",
    "    \n",
    "    # Define the commands to run\n",
    "    commands = {'hostname_command': 'show hostname',\n",
    "                'diff_command': 'show running-config diff',\n",
    "                'interface_status_command': 'show interface status',\n",
    "                'err_disabled_command': 'show interface status err-disabled',\n",
    "                'logging_command': 'show logging last 9999 | grep \"err-disable\\|BPDU\"',\n",
    "                'stp_blocked_ports_command': 'show spanning-tree blockedports',\n",
    "                'vpc_state_command': 'show vpc brief | begin \"vPC domain id\" | end \"vPC Peer-link status\"',\n",
    "                'vpc_status_command': 'show vpc brief | begin \"vPC status\"',\n",
    "                'vpc_consistency_command': 'show vpc consistency-parameters global | grep \"Local suspended\"',\n",
    "                'vpc_keepalive_command': 'show vpc peer-keepalive | grep -v \"ms\\|msec\"',\n",
    "                'get_arp_table_command': 'show ip arp vrf all | begin \"MAC Address\"',\n",
    "                'get_cam_table_command': 'show mac address-table  | begin \"MAC Address\"'}\n",
    "\n",
    "    # Create the extra variables to pass to Ansible\n",
    "    extravars = {'username': username,\n",
    "                 'password': password,\n",
    "                 'host_group': host_group,\n",
    "                 'commands': cmd}\n",
    "\n",
    "    # Execute the pre-checks\n",
    "    runner = ansible_runner.run(private_data_dir='.',\n",
    "                                playbook=f'{play_path}/cisco_nxos_pre_post_checks.yml',\n",
    "                                extravars=extravars)\n",
    "    \n",
    "    # Parse the output; add the hosts to 'devices' and the command output to 'check_data'\n",
    "    for event in runner.events:\n",
    "        if event['event'] == 'runner_on_ok':\n",
    "            event_data = event['event_data']\n",
    "            device = event_data['remote_addr']\n",
    "            \n",
    "            # Create the dictionary keys for 'check_data'\n",
    "            if not check_data.get(device):\n",
    "                check_data[device] = dict()\n",
    "            \n",
    "            # Add the command output to 'check_data'\n",
    "            cmd = event_data['res']['invocation']['module_args']['commands'][0]\n",
    "            output = event_data['res']['stdout'][0].split('\\n')\n",
    "            check_data[device][cmd] = output\n",
    "\n",
    "    return check_data\n",
    "\n",
    "group = 'cts_core_7k'\n",
    "\n",
    "pre_check_data = cisco_nxos_run_checks(username, password, group, play_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8747ff2-a08e-4ec9-a39c-71cabf63c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nxos_checks_dump(check_data):\n",
    "    '''\n",
    "    Formats the output of the 'cisco_nxos_pre_post_checks.yml' playbook and\n",
    "    returns it as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        check_data (dict): The output of the playbooks\n",
    "\n",
    "    Returns:\n",
    "        formatted_checks (dict): A nested dictionary, where the value for each\n",
    "                                 key is the formatted output\n",
    "    '''\n",
    "\n",
    "    nxos_devices = list()\n",
    "    \n",
    "    check_hostnames = dict()\n",
    "    check_hostnames['inventory_name'] = list()\n",
    "    check_hostnames['hostname'] = list()\n",
    "\n",
    "    check_inf_status = dict()\n",
    "    check_inf_status['hostname'] = list()\n",
    "    check_inf_status['Port'] = list()\n",
    "    check_inf_status['Name'] = list()\n",
    "    check_inf_status['Status'] = list()\n",
    "    check_inf_status['Vlan'] = list()\n",
    "    check_inf_status['Duplex'] = list()\n",
    "    check_inf_status['Speed'] = list()\n",
    "    check_inf_status['Type'] = list()\n",
    "\n",
    "    check_vpc_status = dict()\n",
    "    check_vpc_status['hostname'] = list()\n",
    "    check_vpc_status['id'] = list()\n",
    "    check_vpc_status['Port'] = list()\n",
    "    check_vpc_status['Status'] = list()\n",
    "    check_vpc_status['Consistency'] = list()\n",
    "    check_vpc_status['Reason'] = list()\n",
    "    check_vpc_status['Active vlans'] = list()\n",
    "\n",
    "    check_vpc_state = dict()\n",
    "    check_vpc_state['hostname'] = list()\n",
    "    check_vpc_state['vPC domain id'] = list()\n",
    "    check_vpc_state['Peer status'] = list()\n",
    "    check_vpc_state['vPC keep-alive status'] = list()\n",
    "    check_vpc_state['Configuration consistency status'] = list()\n",
    "    check_vpc_state['Per-vlan consistency status'] = list()\n",
    "    check_vpc_state['Type-2 consistency status'] = list()\n",
    "    check_vpc_state['vPC role'] = list()\n",
    "    check_vpc_state['Number of vPCs configured'] = list()\n",
    "    check_vpc_state['Peer Gateway'] = list()\n",
    "    check_vpc_state['Peer gateway excluded VLANs'] = list()\n",
    "    check_vpc_state['Dual-active excluded VLANs'] = list()\n",
    "    check_vpc_state['Graceful Consistency Check'] = list()\n",
    "    check_vpc_state['Operational Layer3 Peer-router'] = list()\n",
    "    check_vpc_state['Auto-recovery status'] = list()\n",
    "\n",
    "    # Extract the ARP table\n",
    "    check_arp_table = dict()\n",
    "    check_arp_table['hostname'] = list()\n",
    "    check_arp_table['Address'] = list()\n",
    "    check_arp_table['Age'] = list()\n",
    "    check_arp_table['MAC Address'] = list()\n",
    "    check_arp_table['Interface'] = list()\n",
    "\n",
    "    # Extract the CAM table\n",
    "    check_cam_table = dict()\n",
    "    check_cam_table['hostname'] = list()\n",
    "    check_cam_table['Legend'] = list()\n",
    "    check_cam_table['VLAN'] = list()\n",
    "    check_cam_table['MAC Address'] = list()\n",
    "    check_cam_table['Type'] = list()\n",
    "    check_cam_table['age'] = list()\n",
    "    check_cam_table['Secure'] = list()\n",
    "    check_cam_table['NTFY'] = list()\n",
    "    check_cam_table['Ports/SWID.SSID.LID'] = list()\n",
    "    \n",
    "    # Extract the spanning-tree blocked ports\n",
    "    check_stp_blocked = dict()\n",
    "    check_stp_blocked['hostname'] = list()\n",
    "    check_stp_blocked['Name'] = list()\n",
    "    check_stp_blocked['Blocked Interfaces List'] = list()\n",
    "    \n",
    "    # Extract the total number of blocked STP ports\n",
    "    check_total_stp_blocked = dict()\n",
    "    check_total_stp_blocked['hostname'] = list()\n",
    "    check_total_stp_blocked['Total Blocked Ports'] = list()\n",
    "\n",
    "    # Extract the total number of err-disabled ports\n",
    "    check_err_disabled = dict()\n",
    "    check_err_disabled['hostname'] = list()\n",
    "    check_err_disabled['Port'] = list()\n",
    "    check_err_disabled['Name'] = list()\n",
    "    check_err_disabled['Status'] = list()\n",
    "    check_err_disabled['Reason'] = list()\n",
    "    \n",
    "    for key, value in check_data.items():\n",
    "        # Extract the hostnames\n",
    "        nxos_devices.append(key)\n",
    "        check_hostnames['inventory_name'].append(key)\n",
    "        check_hostnames['hostname'].append(value['show hostname'][0])\n",
    "\n",
    "        header = value['show interface status err-disabled'][1]\n",
    "        pos_port = header.index('Port')\n",
    "        pos_name = header.index('Name')\n",
    "        pos_status = header.index('Status')\n",
    "        pos_reason = header.index('Reason')\n",
    "        for line in value['show interface status err-disabled'][3:]:\n",
    "            try:\n",
    "                port = line[pos_port:pos_name].strip()\n",
    "                name = line[pos_name:pos_status].strip()\n",
    "                status = line[pos_status:pos_reason].strip()\n",
    "                reason = line[pos_reason:].strip()\n",
    "                check_err_disabled['Port'].append(port)\n",
    "                check_err_disabled['Name'].append(name)\n",
    "                check_err_disabled['Status'].append(status)\n",
    "                check_err_disabled['Reason'].append(reason)\n",
    "                check_err_disabled['hostname'].append(key)\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        num_err_disabled_ports = len(check_err_disabled.get('Port'))\n",
    "        \n",
    "        for line in value['show spanning-tree blockedports'][2:]:\n",
    "            line = line.split()\n",
    "            if len(line) == 2:\n",
    "                check_stp_blocked['hostname'].append(key)\n",
    "                check_stp_blocked['Name'].append(line[0])\n",
    "                check_stp_blocked['Blocked Interfaces List'].append(line[1])\n",
    "            if '(segments)' in line:\n",
    "                check_total_stp_blocked['hostname'].append(key)\n",
    "                check_total_stp_blocked['Total Blocked Ports'].append(line[-1])\n",
    "        \n",
    "        for line in value['show ip arp vrf all | begin \"MAC Address\"'][1:]:\n",
    "            check_arp_table['hostname'].append(key)\n",
    "            check_arp_table['Address'].append(line.split()[0])\n",
    "            check_arp_table['Age'].append(line.split()[1])\n",
    "            check_arp_table['MAC Address'].append(line.split()[2])\n",
    "            check_arp_table['Interface'].append(line.split()[3])        \n",
    "        \n",
    "        for line in value['show mac address-table  | begin \"MAC Address\"'][2:]:\n",
    "            line = line.split()\n",
    "            if len(line) == 8:\n",
    "                check_cam_table['Legend'].append(line[0])\n",
    "                check_cam_table['VLAN'].append(line[1])\n",
    "                check_cam_table['MAC Address'].append(line[2])\n",
    "                check_cam_table['Type'].append(line[3])\n",
    "                check_cam_table['age'].append(line[4])\n",
    "                check_cam_table['Secure'].append(line[5])\n",
    "                check_cam_table['NTFY'].append(line[6])\n",
    "                check_cam_table['Ports/SWID.SSID.LID'].append(line[7])\n",
    "                check_cam_table['hostname'].append(key)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Extract the interface statuses\n",
    "        header = value['show interface status'][1]\n",
    "        pos = header.index('Status')\n",
    "        for line in value['show interface status'][3:]:\n",
    "            # Get the interface\n",
    "            port = line.split()[0]\n",
    "\n",
    "            # Get the interface name (this accounts for devices that change the\n",
    "            # starting position of columns)\n",
    "            line_prefix = line[:pos].split()\n",
    "            name = ' '.join(line_prefix[1:])\n",
    "\n",
    "            # Get the remaining parameters\n",
    "            line_suffix = line[pos:].split()\n",
    "            status = line_suffix[0]\n",
    "            vlan = line_suffix[1]\n",
    "            duplex = line_suffix[2]\n",
    "            speed = line_suffix[3]\n",
    "            try:\n",
    "                port_type = line_suffix[4]\n",
    "            except Exception:\n",
    "                port_type = str()\n",
    "\n",
    "            check_inf_status['hostname'].append(key)\n",
    "            check_inf_status['Port'].append(port)\n",
    "            check_inf_status['Name'].append(name)\n",
    "            check_inf_status['Status'].append(status)\n",
    "            check_inf_status['Vlan'].append(vlan)\n",
    "            check_inf_status['Duplex'].append(duplex)\n",
    "            check_inf_status['Speed'].append(speed)\n",
    "            check_inf_status['Type'].append(port_type)\n",
    "\n",
    "        # Extract the VPC state information\n",
    "        vpc_state = value['show vpc brief | begin \"vPC domain id\" | end \"vPC Peer-link status\"'][:-2]\n",
    "        check_vpc_state['hostname'].append(key)\n",
    "        for line in vpc_state:\n",
    "            line = line.split(':')\n",
    "            line = [l.strip() for l in line]\n",
    "            check_vpc_state[line[0]].append(line[-1])\n",
    "\n",
    "        vpc_status = value['show vpc brief | begin \"vPC status\"'][4:]\n",
    "        vpc_status = [l for l in vpc_status if len(l.split()) != 1]\n",
    "        for line in vpc_status:\n",
    "            line = line.split()\n",
    "            if len(line) == 6 or len(line) == 8:\n",
    "                id_ = line[0]\n",
    "                port = line[1]\n",
    "                status = line[2]\n",
    "                if len(line) == 8:\n",
    "                    consistency = 'Not Applicable'\n",
    "                    reason = 'Consistency Check Not Performed'\n",
    "                else:\n",
    "                    consistency = line[3]\n",
    "                    reason = line[4]\n",
    "                active_vlans = line[-1]\n",
    "                check_vpc_status['hostname'].append(key)\n",
    "                check_vpc_status['id'].append(id_)\n",
    "                check_vpc_status['Port'].append(port)\n",
    "                check_vpc_status['Status'].append(status)\n",
    "                check_vpc_status['Consistency'].append(consistency)\n",
    "                check_vpc_status['Reason'].append(reason)\n",
    "                check_vpc_status['Active vlans'].append(active_vlans)        \n",
    "\n",
    "    if check_vpc_state.get('Peer Gateway'):\n",
    "        vpc_in_use = True\n",
    "    else:\n",
    "        vpc_in_use = False\n",
    "                \n",
    "    formatted_checks = dict()\n",
    "    formatted_checks['check_arp_table'] = check_arp_table\n",
    "    formatted_checks['check_cam_table'] = check_cam_table\n",
    "    formatted_checks['check_err_disabled'] = check_err_disabled\n",
    "    formatted_checks['num_err_disabled_ports'] = num_err_disabled_ports\n",
    "    formatted_checks['check_hostnames'] = check_hostnames\n",
    "    formatted_checks['check_inf_status'] = check_inf_status\n",
    "    formatted_checks['check_stp_blocked'] = check_stp_blocked\n",
    "    formatted_checks['check_total_stp_blocked'] = check_total_stp_blocked\n",
    "    formatted_checks['check_vpc_status'] = check_vpc_status\n",
    "    formatted_checks['check_vpc_state'] = check_vpc_state\n",
    "    formatted_checks['vpc_in_use'] = vpc_in_use\n",
    "                \n",
    "    return formatted_checks\n",
    "\n",
    "\n",
    "pre_formatted_checks = nxos_checks_dump(pre_check_data)\n",
    "pre_check_arp_table = pre_formatted_checks['check_arp_table']\n",
    "pre_check_cam_table = pre_formatted_checks['check_cam_table']\n",
    "pre_check_err_disabled = pre_formatted_checks['check_err_disabled']\n",
    "pre_check_num_err_disabled_ports = pre_formatted_checks['num_err_disabled_ports']\n",
    "pre_check_hostnames = pre_formatted_checks['check_hostnames']\n",
    "pre_check_inf_status = pre_formatted_checks['check_inf_status']\n",
    "pre_check_stp_blocked = pre_formatted_checks['check_stp_blocked']\n",
    "pre_check_total_stp_blocked = pre_formatted_checks['check_total_stp_blocked']\n",
    "pre_check_vpc_status = pre_formatted_checks['check_vpc_status']\n",
    "pre_check_vpc_state = pre_formatted_checks['check_vpc_state']\n",
    "vpc_in_use = pre_formatted_checks['vpc_in_use']\n",
    "\n",
    "df_pre_arp_table = pd.DataFrame.from_dict(pre_check_arp_table)\n",
    "del df_pre_arp_table['Age']\n",
    "# display(df_pre_arp_table)\n",
    "\n",
    "df_pre_hostnames = pd.DataFrame.from_dict(pre_check_hostnames)\n",
    "checks['nxos']['hostnames'] = df_pre_hostnames\n",
    "display(df_pre_hostnames)\n",
    "\n",
    "if pre_check_num_err_disabled_ports:\n",
    "    df_pre_err_disabled = pd.DataFrame.from_dict(pre_check_err_disabled)\n",
    "    checks['nxos']['err_disabled_ports'] = df_pre_err_disabled\n",
    "    display(df_pre_err_disabled)\n",
    "\n",
    "df_pre_check_stp_blocked = pd.DataFrame.from_dict(pre_check_stp_blocked)\n",
    "checks['nxos']['stp_blocked_ports'] = df_pre_check_stp_blocked\n",
    "# display(df_pre_check_stp_blocked)\n",
    "\n",
    "df_pre_check_total_stp_blocked = pd.DataFrame.from_dict(pre_check_total_stp_blocked)\n",
    "checks['nxos']['total_stp_blocked_ports'] = df_pre_check_total_stp_blocked\n",
    "# display(df_pre_check_total_stp_blocked)\n",
    "\n",
    "df_pre_inf_status = pd.DataFrame.from_dict(pre_check_inf_status)\n",
    "checks['nxos']['interface_statuses'] = df_pre_inf_status\n",
    "# display(df_pre_inf_status)\n",
    "\n",
    "df_arp_table = pd.DataFrame.from_dict(pre_check_arp_table)\n",
    "checks['nxos']['arp_table'] = df_arp_table\n",
    "\n",
    "df_pre_cam_table = pd.DataFrame.from_dict(pre_check_cam_table)\n",
    "checks['nxos']['cam_table'] = df_pre_cam_table\n",
    "# display(df_pre_cam_table)\n",
    "\n",
    "if vpc_in_use:\n",
    "    df_pre_vpc_state = pd.DataFrame.from_dict(pre_check_vpc_state)\n",
    "    checks['nxos']['vpc_state'] = df_pre_vpc_state\n",
    "    display(df_pre_vpc_state)\n",
    "\n",
    "    df_pre_vpc_status = pd.DataFrame.from_dict(pre_check_vpc_status)\n",
    "    checks['nxos']['vpc_status'] = df_pre_vpc_status\n",
    "    display(df_pre_vpc_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90eec8-c8fa-459c-acd1-d7d54dd5f4f6",
   "metadata": {},
   "source": [
    "## F5 Pre-checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f8a1a-fc78-468f-b336-49f7a8c2e8c3",
   "metadata": {},
   "source": [
    "### Implementation: Run Pre-checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5501009-aee1-4bc0-82a9-ab5bc5f28ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'f5_ltm_cts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c359c5-ea17-4d17-9c30-f641badb994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds = {'show_hostname': 'list sys global-settings hostname | grep hostname',\n",
    "        'sync_status': 'show cm sync-status | grep Status | grep -v CM',\n",
    "        'sys_version': 'show sys version | grep Version | grep -v Sys',\n",
    "        'total_vips': 'list ltm virtual /*/* | grep -c \"ltm virtual\"',\n",
    "        'vip_availability': 'show ltm virtual /*/* | grep \"Ltm::\\|Availability\"',\n",
    "        'available_vips': 'show ltm virtual /*/* | grep Availability | grep -c available',\n",
    "        'vip_destinations': 'show ltm virtual /*/* | grep \"Virtual Server\\|Availability\\|Destination\"',\n",
    "        'active_pool_members': 'show ltm pool /*/* | grep \"Current Active Members\"',\n",
    "        'pool_member_availability': 'show ltm pool /*/* members detail | grep \"Ltm::Pool\\|Availability\"',\n",
    "        'get_arp_table': 'show net arp | grep -v \"\\-\\-\\-\\|Net::Arp\\|HWaddress\"',  # TODO: Does this command display ARP entries for all partitions?\n",
    "        'get_cam_table': 'show sys mac-address | grep \"mac-address\"',\n",
    "        'show_net_interface': 'show net interface | grep -v \"\\-\\-\\-\\|Net::Interface\\|Bits\\|Out\"',\n",
    "        'list_net_interface': 'list net interface',\n",
    "        # 'get_irules': 'list ltm rule /*/*'\n",
    "       }\n",
    "\n",
    "extravars = {'host_group': group,\n",
    "             'user': username,\n",
    "             'password': password,\n",
    "             'validate_certs': 'no'}\n",
    "\n",
    "for cmd in cmds:\n",
    "    extravars[cmd] = cmds[cmd]\n",
    "    \n",
    "devices = list()\n",
    "\n",
    "results = dict()\n",
    "\n",
    "runner = ansible_runner.run(private_data_dir='.',\n",
    "                            playbook=f'{play_path}/f5_pre_post_checks.yml',\n",
    "                            extravars=extravars)\n",
    "\n",
    "print(f'{runner.status}: {runner.rc}')\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for event in runner.events:\n",
    "    if event['event'] == 'runner_on_ok':\n",
    "        # Parse the event to extract the data\n",
    "        event_data = event['event_data']\n",
    "        host = event_data['host']\n",
    "        cmd = event_data['res']['invocation']['module_args']['commands'].pop()\n",
    "        result = event_data['res']['stdout'][0]\n",
    "\n",
    "        # If a nested dictionary for the host does not yet exist, then create it\n",
    "        if not results.get(host):\n",
    "            results[host] = dict()\n",
    "\n",
    "        # Map the command to the corresponding key in the 'cmds' dictionary and add\n",
    "        # it to the result.\n",
    "        for key, value in cmds.items():\n",
    "            if value == cmd:\n",
    "                results[host][key] = result\n",
    "                break\n",
    "\n",
    "        # Add the host to the 'devices' list\n",
    "        if host not in devices:\n",
    "            devices.append(host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda946c-b843-4396-b5fe-5280275a0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the pre-check data\n",
    "pre_checks = dict()\n",
    "pre_checks['device'] = list()\n",
    "for cmd in cmds:\n",
    "    pre_checks[cmd] = list()\n",
    "\n",
    "# Remove dictionary keys that we do not need for 'df_pre'\n",
    "excluded_cmds = ['vip_availability',\n",
    "                 'pool_member_availability',\n",
    "                 'get_arp_table',\n",
    "                 'get_cam_table',\n",
    "                 # 'show_net_interface',\n",
    "                 'vip_destinations',\n",
    "                 'list_net_interface'\n",
    "                 ]\n",
    "# for cmd in excluded_cmds:\n",
    "#     del pre_checks[cmd]\n",
    "\n",
    "# Parse the 'results' dictionary and add the applicable output to 'df_pre'\n",
    "for device in devices:\n",
    "    for key, value in results[device].items():\n",
    "        if key == 'show_hostname':\n",
    "            # pprint(value)\n",
    "            hostname = value.split()[-1]\n",
    "        if key == 'sync_status':\n",
    "            sync_status = value.split('Status')[-1].strip()\n",
    "        if key == 'sys_version':\n",
    "            sys_version = value.split()[-1]\n",
    "        if key == 'total_vips':\n",
    "            total_vips = value\n",
    "        if key == 'available_vips':\n",
    "            available_vips = value\n",
    "\n",
    "        if key == 'vip_destinations':\n",
    "            vip_destinations = dict()\n",
    "            vip_destinations['hostname'] = list()\n",
    "            vip_destinations['name'] = list()\n",
    "            vip_destinations['availability'] = list()\n",
    "            vip_destinations['destination'] = list()\n",
    "            vip_destinations['port'] = list()\n",
    "            for line in value.split('\\n'):\n",
    "                if line.split()[0] == 'Ltm::Virtual':\n",
    "                    vip_destinations['hostname'].append(device)\n",
    "                    name = line.split()[-1]\n",
    "                    vip_destinations['name'].append(name)\n",
    "                if line.split()[0] == 'Availability':\n",
    "                    availability = line.split()[-1]\n",
    "                    vip_destinations['availability'].append(availability)\n",
    "                if line.split()[0] == 'Destination':\n",
    "                    destination = line.split()[-1].split(':')[0]\n",
    "                    vip_destinations['destination'].append(destination)\n",
    "                    port = line.split()[-1].split(':')[-1]\n",
    "                    vip_destinations['port'].append(port)\n",
    "            df_vip_destinations = pd.DataFrame.from_dict(vip_destinations)\n",
    "            \n",
    "        if key == 'active_pool_members':\n",
    "            num_members = 0\n",
    "            for line in value.split('\\n'):\n",
    "                num_members += int(line.split()[-1])\n",
    "            active_pool_members = str(num_members)\n",
    "        if key == 'show_net_interface':\n",
    "            num_up_interfaces = 0\n",
    "            for line in value.split('\\n'):\n",
    "                if line.split()[1] == 'up':\n",
    "                    num_up_interfaces += 1\n",
    "    \n",
    "    # Add the results to the 'pre_checks' dictionary\n",
    "    pre_checks['device'].append(device)\n",
    "    pre_checks['show_hostname'].append(hostname)\n",
    "    pre_checks['sync_status'].append(sync_status)\n",
    "    pre_checks['sys_version'].append(sys_version)\n",
    "    pre_checks['total_vips'].append(total_vips)\n",
    "    pre_checks['available_vips'].append(available_vips)\n",
    "    pre_checks['active_pool_members'].append(active_pool_members)\n",
    "    pre_checks['show_net_interface'].append(num_up_interfaces)\n",
    "\n",
    "# Try to delete the 'df_pre' dataframe. This is to avoid corruption if it is recreated\n",
    "try:\n",
    "    del df_pre\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Remove from 'pre_checks' any keys that are in excluded_cmds\n",
    "to_delete = list()\n",
    "for key, value in pre_checks.items():\n",
    "    if key in excluded_cmds:\n",
    "        to_delete.append(key)\n",
    "for cmd in to_delete:\n",
    "    del pre_checks[cmd]\n",
    "\n",
    "checks['f5s']['summary'] = pd.DataFrame.from_dict(pre_checks)\n",
    "\n",
    "display(checks['f5s']['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84069aea-6736-47b1-a2dd-0d2dbd718ea9",
   "metadata": {},
   "source": [
    "### Create Additional Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604aca6-0571-483f-af19-f1321b36643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for individual pool member states\n",
    "pre_member_states = dict()\n",
    "pre_member_states['device'] = list()\n",
    "pre_member_states['pool_name'] = list()\n",
    "pre_member_states['pool_member'] = list()\n",
    "pre_member_states['pool_member_state'] = list()\n",
    "\n",
    "# Iterate through 'results', adding pool members states to 'pre_member_states'\n",
    "for device in devices:\n",
    "    member_states = results[device]['pool_member_availability'].split('\\n')\n",
    "    for line in member_states:\n",
    "        if 'Ltm::Pool:' in line:\n",
    "            pool_name = line.split('Ltm::Pool: ')[-1]\n",
    "            try:\n",
    "                pos = member_states.index(line)+1\n",
    "                while 'Ltm::Pool:' not in member_states[pos]:\n",
    "                    if '| Ltm::Pool Member:' in member_states[pos]:\n",
    "                        pool_member = member_states[pos].split('Ltm::Pool Member: ')[-1]\n",
    "                        pool_member_state = member_states[pos+1].split(':')[-1].strip()\n",
    "\n",
    "                        pre_member_states['device'].append(device)\n",
    "                        pre_member_states['pool_name'].append(pool_name)\n",
    "                        pre_member_states['pool_member'].append(pool_member)\n",
    "                        pre_member_states['pool_member_state'].append(pool_member_state)\n",
    "                    pos += 1\n",
    "            except Exception as e:\n",
    "                if str(e) == 'list index out of range':\n",
    "                    break\n",
    "                else:\n",
    "                    print(str(e))\n",
    "                    \n",
    "# Try to delete 'df_pre_member_state'\n",
    "try:\n",
    "    del df_pre_member_state\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create 'df_pre_member_state'\n",
    "df_pre_member_state = pd.DataFrame.from_dict(pre_member_states)\n",
    "checks['f5s']['pool_member_states'] = df_pre_member_state\n",
    "\n",
    "display(df_pre_member_state.head(10))\n",
    "\n",
    "# Create a dataframe for individual VIP states\n",
    "pre_vip_states = dict()\n",
    "pre_vip_states['device'] = list()\n",
    "pre_vip_states['vip_name'] = list()\n",
    "pre_vip_states['vip_state'] = list()\n",
    "\n",
    "# Iterate through 'results', adding VIP states to 'pre_vip_states'\n",
    "for device in devices:\n",
    "    vip_availability = results[device]['vip_availability'].split('\\n')\n",
    "    for line in vip_availability:\n",
    "        if 'Ltm::Virtual Server:' in line:\n",
    "            # Get the position of the line in the list\n",
    "            pos = vip_availability.index(line)\n",
    "\n",
    "            # Use the position to get the VIP availability\n",
    "            vip_state = vip_availability[pos+1].split()[-1]\n",
    "            \n",
    "            # Extract the VIP name from the line\n",
    "            vip_name = line.split('Ltm::Virtual Server: ')[-1]\n",
    "\n",
    "            # Add the data to 'pre_vip_states'\n",
    "            pre_vip_states['device'].append(device)\n",
    "            pre_vip_states['vip_name'].append(vip_name)\n",
    "            pre_vip_states['vip_state'].append(vip_state)\n",
    "            \n",
    "# Try to delete 'df_pre_vip_state'\n",
    "try:\n",
    "    del df_pre_vip_state\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create 'df_pre_vip_state'\n",
    "df_pre_vip_state = pd.DataFrame.from_dict(pre_vip_states)\n",
    "checks['f5s']['vip_states'] = df_pre_vip_state\n",
    "display(df_pre_vip_state.head(10))\n",
    "\n",
    "# Create a dataframe for the ARP table\n",
    "# Define the dataframe columns\n",
    "cols = ['name',\n",
    "        'address',\n",
    "        'hw_address',\n",
    "        'vlan',\n",
    "        'expire_in_sec',\n",
    "        'status']\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary to store the ARP table data\n",
    "pre_arp = dict()\n",
    "pre_arp['device'] = list()\n",
    "for c in cols:\n",
    "    pre_arp[c] = list()\n",
    "\n",
    "# Iterate through 'results', adding ARP table data to 'pre_arp'\n",
    "for device in devices:\n",
    "    arp_table = results[device]['get_arp_table'].split('\\n')\n",
    "    for line in arp_table:\n",
    "        pre_arp['device'].append(device)\n",
    "        pre_arp['name'].append(line.split()[0])\n",
    "        pre_arp['address'].append(line.split()[1])\n",
    "        pre_arp['hw_address'].append(line.split()[2])\n",
    "        pre_arp['vlan'].append(line.split()[3])\n",
    "        pre_arp['expire_in_sec'].append(line.split()[4])\n",
    "        pre_arp['status'].append(line.split()[5])\n",
    "            \n",
    "# Try to delete 'pre_arp'\n",
    "try:\n",
    "    del df_pre_arp\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create 'df_pre_arp'\n",
    "df_pre_arp = pd.DataFrame.from_dict(pre_arp)\n",
    "checks['f5s']['arp_table'] = df_pre_arp\n",
    "display(df_pre_arp.head(10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a dataframe for the CAM table\n",
    "cols = ['device',\n",
    "        'entry',\n",
    "        'component',\n",
    "        'object_id',\n",
    "        'property']\n",
    "\n",
    "# Create a dictionary to store the CAM table data\n",
    "pre_cam = dict()\n",
    "pre_cam['device'] = list()\n",
    "for c in cols:\n",
    "    pre_cam[c] = list()\n",
    "\n",
    "# Iterate through 'results', adding ARP table data to 'pre_arp'\n",
    "for device in devices:\n",
    "    cam_table = results[device]['get_cam_table'].split('\\n')\n",
    "    for line in cam_table:\n",
    "        pre_cam['device'].append(device)\n",
    "        pre_cam['entry'].append(line.split()[0])\n",
    "        pre_cam['component'].append(line.split()[1])\n",
    "        pre_cam['object_id'].append(line.split()[2])\n",
    "        pre_cam['property'].append(line.split()[3])\n",
    "            \n",
    "# Try to delete 'df_pre_cam'\n",
    "try:\n",
    "    del df_pre_cam\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create 'df_pre_cam'\n",
    "df_pre_cam = pd.DataFrame.from_dict(pre_cam)\n",
    "checks['f5s']['cam_table'] = df_pre_cam\n",
    "display(df_pre_cam.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c7867-ee06-40a1-9ab0-2bb80069b931",
   "metadata": {},
   "source": [
    "### Use NMAP To Scan Available VIP Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c22b44-c42f-49ec-ad44-8dd199e1565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_all = df_vip_destinations['destination'].to_list()\n",
    "destinations_any = df_vip_destinations.loc[df_vip_destinations['port'] == 'any']['destination'].to_list()\n",
    "\n",
    "ports = df_vip_destinations['port'].to_list()\n",
    "ports = [p for p in ports if p != 'any']\n",
    "ports = list(set(ports))\n",
    "\n",
    "top_port = 0\n",
    "for p in ports:\n",
    "    if int(p) > top_port:\n",
    "        top_port = int(p)\n",
    "\n",
    "len(df_vip_destinations), len(destinations_all), len(destinations_any), len(ports), top_port\n",
    "\n",
    "checks['f5s']['vip_destinations'] = df_vip_destinations\n",
    "\n",
    "display(checks['f5s']['vip_destinations'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bedce26-6d7d-4a63-9d99-2aad7f4c817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmap = nmap3.Nmap()\n",
    "print('Scanning destinations that have defined ports')\n",
    "results_unique = nmap.scan_top_ports(' '.join(destinations_all),\n",
    "                                     args=f'-np {\",\".join(ports)}',\n",
    "                                     default=top_port)\n",
    "\n",
    "print('Doing a \"top ports\" scan of ports with a destination of \"any\"')\n",
    "results_any = nmap.scan_top_ports(' '.join(destinations_any),\n",
    "                                  args='-n')\n",
    "\n",
    "def remove_invalid_keys(result):\n",
    "    invalid_keys = list()\n",
    "    for key in result:\n",
    "        try:\n",
    "            if ipaddress.ip_address(key):\n",
    "                pass\n",
    "        except Exception:\n",
    "            invalid_keys.append(key)\n",
    "    for key in invalid_keys:\n",
    "        del result[key]\n",
    "    return result\n",
    "\n",
    "results_unique = remove_invalid_keys(results_unique)\n",
    "results_any = remove_invalid_keys(results_any)\n",
    "      \n",
    "len(df_vip_destinations), len(results_unique), len(results_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2be95-f0f2-4155-a04f-bc300fd996e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ports = list()\n",
    "closed_ports = list()\n",
    "\n",
    "scan_dict = dict()\n",
    "for key, value in results_unique.items():\n",
    "    scan_dict[key] = dict()\n",
    "    scan_dict[key]['open'] = list()\n",
    "    scan_dict[key]['closed'] = list()\n",
    "    \n",
    "    for item in value['ports']:\n",
    "        if item.get('state'):\n",
    "            port = item.get('portid')\n",
    "            state = item.get('state')\n",
    "            if state == 'open':\n",
    "                scan_dict[key]['open'].append(port)\n",
    "            else:\n",
    "                scan_dict[key]['closed'].append(port)\n",
    "\n",
    "for key, value in results_any.items():\n",
    "    if not scan_dict.get(key):\n",
    "        scan_dict[key] = dict()\n",
    "        scan_dict[key]['open'] = list()\n",
    "        scan_dict[key]['closed'] = list()\n",
    "    \n",
    "    for item in value['ports']:\n",
    "        if item.get('state'):\n",
    "            state = item.get('state')\n",
    "            port = item.get('portid')\n",
    "            \n",
    "            if state == 'open':\n",
    "                scan_dict[key]['open'].append(port)\n",
    "            else:\n",
    "                scan_dict[key]['closed'].append(port)            \n",
    "        \n",
    "for idx, row in df_vip_destinations.iterrows():\n",
    "    destination = row['destination']\n",
    "    if scan_dict.get(destination):\n",
    "        p_open = ' '.join(scan_dict[destination].get('open'))\n",
    "        p_closed = ' '.join(scan_dict[destination].get('closed'))\n",
    "        \n",
    "    else:\n",
    "        p_open = 'unknown'\n",
    "        p_closed = 'unknown'\n",
    "        \n",
    "    open_ports.append(p_open)\n",
    "    closed_ports.append(p_closed)\n",
    "\n",
    "df_vip_destinations['open ports'] = open_ports\n",
    "df_vip_destinations['closed ports'] = closed_ports\n",
    "    \n",
    "len(df_vip_destinations), len(open_ports), len(closed_ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1935d4-f01f-41f9-bc22-271594b5d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_http = df_vip_destinations.loc[df_vip_destinations['availability'] == 'available'].copy()\n",
    "\n",
    "df_available_http_vips = df_http.loc[(df_http['port'] == '80') |\n",
    "                                     (df_http['port'] == '443') | \n",
    "                                     (df_http['port'] == '8080')]\n",
    "\n",
    "checks['f5s']['available_http_vips'] = df_available_http_vips\n",
    "\n",
    "display(df_available_http_vips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50701870-02d5-46a1-bfc9-49652ff30b88",
   "metadata": {},
   "source": [
    "### Check if Web Site Responds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee02df-3625-4443-abfc-ee3496afebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_responses = dict()\n",
    "http_responses['name'] = list()\n",
    "http_responses['destination'] = list()\n",
    "http_responses['size'] = list()\n",
    "http_responses['error'] = list()\n",
    "\n",
    "for idx, row in df_available_http_vips.iterrows():\n",
    "    destination = row['destination']\n",
    "    website = f'http://{destination}'\n",
    "    try:\n",
    "        r = requests.get(website, timeout=15)\n",
    "        http_responses['name'].append(row['name'])\n",
    "        http_responses['destination'].append(destination)\n",
    "        http_responses['size'].append(len(r.content))\n",
    "        error = str(0)\n",
    "        http_responses['error'].append(error)\n",
    "    except Exception as e:\n",
    "        http_responses['name'].append(row['name'])\n",
    "        http_responses['destination'].append(destination)\n",
    "        http_responses['size'].append(0)\n",
    "        error = str(e)\n",
    "        http_responses['error'].append(error)\n",
    "\n",
    "df_http_responses = pd.DataFrame.from_dict(http_responses)\n",
    "\n",
    "checks['f5s']['http_responses'] = df_http_responses\n",
    "\n",
    "display(df_http_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce1138-6223-4053-8211-126e47e8145d",
   "metadata": {},
   "source": [
    "# Save the Checks to a Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150cb58-7594-426b-989b-ed5e01033b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = set_filename(filepath)\n",
    "filename\n",
    "\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    for key, value in checks.items():\n",
    "        for k, v in value.items():\n",
    "            sheet_name = f'{key}_{k}'\n",
    "            v.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "print(f'File saved to {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5551a-5f34-49e9-bc96-624b63dff3f2",
   "metadata": {},
   "source": [
    "## Compare Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d181a6c-2c8e-4d1a-b859-511ca24743d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_files = input('Enter the names (comma-delimited) of two spreadsheets to compare: ')\n",
    "comp_files = [f.strip() for f in comp_files.split(',')]\n",
    "comp_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40361c95-aa72-4738-83c2-b109d7a57dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del dict_1\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del dict_2\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "dict_1 = pd.read_excel(comp_files[0], sheet_name=None)\n",
    "dict_2 = pd.read_excel(comp_files[1], sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689223f7-f121-4d21-9ae3-7d2456c99063",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_dict = dict()\n",
    "status_dict['f5s_pool_member_states'] = list()\n",
    "status_dict['f5s_vip_states'] = list()\n",
    "status_dict['f5s_arp_table'] = list()\n",
    "status_dict['f5s_vip_destinations'] = list()\n",
    "status_dict['f5s_available_http_vips'] = list()\n",
    "\n",
    "for key, value in dict_1.items():\n",
    "    try:\n",
    "        del df_1\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        del df_2\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    df_1 = value.copy()\n",
    "    df_2 = dict_2[key].copy()\n",
    "    \n",
    "    if key == 'f5s_summary':\n",
    "        display(df_1)\n",
    "        display(df_2)\n",
    "    \n",
    "    if key == 'f5s_pool_member_states':\n",
    "        status_dict[key].append(len(df_1.loc[df_1['pool_member_state'] == 'available']))\n",
    "        status_dict[key].append(len(df_2.loc[df_2['pool_member_state'] == 'available']))                     \n",
    "        # print(key, len(df_1.loc[df_1['pool_member_state'] == 'available']), len(df_2.loc[df_2['pool_member_state'] == 'available']))\n",
    "        \n",
    "    if key == 'f5s_vip_states':\n",
    "        status_dict[key].append(len(df_1.loc[df_1['vip_state'] == 'available']))\n",
    "        status_dict[key].append(len(df_2.loc[df_2['vip_state'] == 'available']))\n",
    "        # print(key, len(df_1.loc[df_1['vip_state'] == 'available']), len(df_2.loc[df_2['vip_state'] == 'available']))\n",
    "        \n",
    "    if key == 'f5s_arp_table':\n",
    "        status_dict[key].append(len(df_1.loc[df_1['status'] == 'resolved']))\n",
    "        status_dict[key].append(len(df_2.loc[df_2['status'] == 'resolved']))\n",
    "        # print(key, len(df_1.loc[df_1['status'] == 'resolved']), len(df_2.loc[df_2['status'] == 'resolved']))\n",
    "        \n",
    "    if key == 'f5s_vip_destinations':\n",
    "        status_dict[key].append(len(df_1.loc[df_1['availability'] == 'available']))\n",
    "        status_dict[key].append(len(df_2.loc[df_2['availability'] == 'available']))\n",
    "        # print(key, len(df_1.loc[df_1['availability'] == 'available']), len(df_2.loc[df_2['availability'] == 'available']))\n",
    "\n",
    "    if key == 'f5s_available_http_vips':\n",
    "        status_dict[key].append(len(df_1.loc[df_1['availability'] == 'available']))\n",
    "        status_dict[key].append(len(df_2.loc[df_2['availability'] == 'available']))\n",
    "\n",
    "df_status = pd.DataFrame.from_dict(status_dict).T\n",
    "# df_status.rename(columns = {'0': comp_files[0], '1': comp_files[1]}, inplace=True)\n",
    "df_status.columns = [comp_files[0], comp_files[1]]\n",
    "\n",
    "display(df_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d23f2-d076-4256-846c-1c9f4a839066",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_1.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25144a8-80ed-44d9-8222-55ae67c1aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_1.items():\n",
    "    print(key)\n",
    "    print('\\n')\n",
    "    print(value.info())\n",
    "    print(dict_2[key].info())\n",
    "    display(value.head(10))\n",
    "    display(dict_2[key].head(10))\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
